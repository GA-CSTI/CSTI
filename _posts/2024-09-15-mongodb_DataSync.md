---
title: "[MongoDB] MongoDB 데이터 동기화 및 압축"
excerpt: "MongoDB의 공유 캐시와 디스크 간의 데이터 동기화 과정과 캐시 효율성을 높이기 위한 운영체제 캐시 사용 여부, MongoDB의 데이터 페이지 압축에 대한 내용을 정리하였습니다."
#layout: archive
categories:
 - Mongodb
tags:
  - [mongodb]
#permalink: mongodb-first
toc: true
toc_sticky: true
date: 2024-09-15
last_modified_at: 2024-09-15
comments: true
---
### 🚀 MongoDB Lock Free 알고리즘(내부 잠금경합 최소화)
Real MongoDB 서적의 이론을 토대로 MongoDB의 공유 캐시와 디스크 간의 데이터 동기화 과정과 캐시 효율성을 높이기 위한 운영체제 캐시 사용 여부, MongoDB의 데이터 페이지 압축에 대한 내용을 정리하였습니다.
<br/>



### 🚀 캐시 이빅션

WiredTiger 스토리지 엔진은 공유 캐시를 위해서 지정된 크기의 메모리 공간만 사용해야 하는데, 이를 위해 공유 캐시 내에 새로운 디스크 데이터 페이지를 읽어서 적재할 수 있도록 빈 공간을 항상 적절히 유지해야 합니다. 그렇지 않으면 쿼리가 필요한 데이터 페이지를 디스크에서 가져오지 못하기 때문에 쿼리의 응답 속도가 느려집니다.

WiredTiger 스토리지 엔진은 공유 캐시에 적절한 빈 공간을 유지하기 위해서 **이빅션 모듈**을 가지고 있으며, 이를 "이빅션 서버(Eviction Server)"라고도 표현합니다. 이빅션 서버는 사용자의 요청을 처리하는 쓰레드(이를 유저 쓰레드 또는 포그라운드 쓰레드라고도 함)와는 별개로 **백그라운드 쓰레드**로 실행되며, 공유 캐시에 적재된 데이터 페이지 중에서 자주 사용되지 않는 데이터 페이지 위주로 공유 캐시에서 제거하는 작업을 수행합니다. 

WiredTiger 스토리지 엔진은 공유 캐시에 적재된 데이터 페이지를 스캔하면서 자주 사용되지 않는 페이지를 제거하는데, 이 과정에서 공유 캐시 스캔을 상당히 많이 수행하게 되기 때문에 모니터링이 필요할 수 있습니다. 이빅션 서버의 작업 상태를 측정 할 수 있는 지표들이 있는데 아래와 같습니다.

- **Total Cache Bytes**  
   = `db.serverStatus() wiredTiger.cache."maximum bytes configured"`

- **Used Cache Bytes**  
   = `db.serverStatus() wiredTiger.cache."bytes currently in the cache"`

- **Dirty Cache Bytes**  
   = `db.serverStatus() wiredTiger.cache."tracked dirty bytes in the cache"`

- **Tree Walks for Eviction**  
   = `db.serverStatus() wiredTiger.cache."pages walked for eviction"`

WiredTiger 스토리지 엔진의 백그라운드 이빅션 쓰레드가 적절히 공유 캐시의 여유 공간을 확보하지 못하면 WiredTiger 스토리지 엔진에서는 사용자의 쿼리를 처리하는 포그라운드 쓰레드에서 직접 캐시 이빅션을 실행하기도 합니다. 이런 상황이 되면 쿼리를 처리해야 할 쓰레드들이 캐시 이빅션까지 처리해야 하기 때문에 MongoDB의 쿼리 처리 성능이 떨어지게 됩니다. 이러한 현상을 측정할 수 있는 지표들은 다음과 같습니다.

- **Evicted by Application Thread**  
   = `db.serverStatus() wiredTiger.cache."pages evicted by application threads"`

- **Evicted by Worker Thread**  
   = `db.serverStatus() wiredTiger.cache."eviction worker thread evicting pages"`


WiredTiger 스토리지 엔진의 이빅션 모듈의 작동 방식을 튜닝할 수 있는 옵션으로는 다음과 같은 것들이 있습니다.

- **threads_max**: 공유 캐시에서 사용되지 않는 데이터 페이지를 제거하는 이빅션 쓰레드를 최대 몇 개까지 사용할 것인지 설정합니다. 쓰레드는 최소 1개부터 20개까지 설정 가능합니다.

- **threads_min**: 공유 캐시에서 사용되지 않는 데이터 페이지를 제거하는 이빅션 쓰레드를 최소 몇 개부터 사용할 것인지 설정합니다. 쓰레드는 최소 1개부터 20개까지 설정 가능합니다. 처음에는 `threads_min`에 설정된 개수의 이빅션 쓰레드로 작동하다가 데이터 페이지를 더 빨리 공유 캐시에서 제거해야 하면 최대 `threads_max`에 설정된 개수까지 쓰레드를 생성합니다.

- **eviction_dirty_target**: 공유 캐시에서 더티 페이지의 비율이 `eviction_dirty_target`에 설정한 비율을 넘지 않도록 유지합니다. 비율은 전체 캐시 크기 대비 더티 페이지의 비율로 설정됩니다. 기본값은 80%입니다.

- **eviction_target**: 공유 캐시에서 데이터 페이지의 비율(전체 캐시 대비 사용률)이 `eviction_target`에 설정한 비율을 넘지 않도록 유지합니다. 비율은 전체 캐시 크기 대비 데이터 페이지가 사용 중인 크기의 비율로 설정됩니다. 기본값은 80%입니다.

- **eviction_trigger**: 전체 공유 캐시 크기 대비 데이터 페이지의 사용률이 `eviction_trigger`를 넘어서면 사용자 쓰레드의 이빅션을 시작합니다. 이빅션 쓰레드(백그라운드)의 페이지 제거 작업은 `eviction_trigger` 설정값과 무관하게 항상 작동합니다.


### 🚀 체크포인트
---

WiredTiger 스토리지 엔진도 사용자의 요청을 빠르게 처리하면서 커밋된 트랜잭션의 영속성을 보장하기 위해서 트랜잭션 로그(WAL, 저널 로그)를 먼저 기록하고, 데이터 파일에 기록하는 작업은 사용자의 트랜잭션과 관계없이 뒤로 미루어서 처리합니다. 이러한 트랜잭션 DBMS들은 모두 체크포인트(Checkpoint)라는 개념을 가지고 있는데, 체크포인트는 데이터 파일과 트랜잭션 로그가 동기화되는 시점을 의미합니다. 체크포인트는 주기적으로 실행되며, 체크포인트가 실행되어야만 오래된 트랜잭션 로그를 삭제하거나 새로운 트랜잭션 로그로 덮어쓸 수 있습니다.

체크포인트는 DBMS 서버가 크래시되거나 서버가 응답 불능 상태로 비정상 종료되었다가 재시작되었을 때, 복구를 시작할 시점을 결정하는 기준이 됩니다. 따라서 체크포인트 간격이 너무 길면 DBMS 서버의 복구 시간(MTTR - Mean Time To Recovery)이 길어지고, 너무 빈번하게 체크포인트가 발생하면 DBMS 서버가 쿼리를 처리하는 능력이 저하됩니다. 


MySQL 서버의 InnoDB 스토리지 엔진은 퍼지(Fuzzy) 체크포인트 방식을 사용합니다. 퍼지 체크포인트는 강제로 데이터 파일과 트랜잭션 로그를 최근 시점의 트랜잭션으로 동기화하는 것이 아니라, 조금씩 더티 페이지를 디스크로 동기화 하는 방식입니다. 이를 수행하기 위해 비동기 방식으로 일정 주기마다 더티 페이지를 내려쓰는 작업을 합니다. 이 방식은 문제가 발생했을 때 복구 시간이 조금 더 길어지지만, 체크포인트 실행 시점에 과도한 디스크 쓰기(더티 페이지의 데이터 파일 동기화)를 피할 수 있습니다. 

WiredTiger 스토리지 엔진은 샤프 체크포인트(Sharp checkpoint) 방식을 채택하고 있습니다. 샤프 체크포인트 방식은 평상시에는 디스크 쓰기가 많지 않지만, 체크포인트가 실행되는 시점에 한꺼번에 더티 페이지를 기록하는 패턴이 나타납니다. WiredTiger 스토리지 엔진은 평상시에는 쓰기를 거의 하지 않고 체크포인트가 발생하는 시점에 상당한 쓰기가 순간적으로 발생합니다. 이렇게 순간적으로 많은 쓰기가 발생하면 동일 시점에 디스크 데이터 파일에서 데이터를 읽어야 하는 쿼리들이 처리 지연되고, 이로 인해 시스템 부하가 높아질 수 있습니다. 

WiredTiger 스토리지 엔진은 기존 데이터 페이지를 덮어쓰지 않고 새로운 페이지 공간을 할당받아 저장하는 특징이 있습니다. 이렇게 새롭게 할당 받은 공간에 내려쓴 뒤 기존의 페이지 공간은 삭제되어 빈공간으로 반환합니다. 이러한 과정으로 WiredTiger 스토리지 엔진의 데이터 파일은 크래시 상황에서 트랜잭션 로그 복구 과정 없이 마지막 체크포인트의 데이터 상태를 유지할 수 있습니다.

WiredTiger의 체크포인트는 데이터 파일의 공간 활용 면에서 보면 다소 불리한 부분도 있습니다. 예를 들어 B-Tree의 모든 페이지가 변경되었다고 가정하면, WiredTiger 스토리지 엔진은 체크포인트 시점에 모든 B-Tree 노드를 디스크 데이터 파일에 기록하여 완전히 새로운 B-Tree를 만듭니다. 그래서 최악의 경우 체크포인트가 실행되면 기존 데이터 파일의 크기가 2배가 될 수도 있습니다. 그러나 이는 공간적인 측면에서 불리한 점이지, WiredTiger 스토리지 엔진의 체크포인트 방식으로 인해 더 많은 디스크 쓰기가 발생하는 것은 아닙니다.


MongoDB 3.2 버전부터는 레플리카 셋의 데이터 일관성과 빠른 페일오버(프라이머리 선출)를 위해서 세컨드리(투표권을 가진 세컨드리)의 데이터가 디스크에 영구적으로 보관되도록 강제하고 있습니다. WiredTiger 스토리지 엔진의 저널 로그가 활성화되지 않은 경우(`storage.journal.enabled` 옵션이 `false`로 설정된 경우)에는 데이터의 영구적인 보관을 위해 변경된 데이터를 항상 파일에 동기화해두어야 합니다. 이를 위해 MongoDB 3.2 버전부터 레플리카 셋에 투입된 세컨드리 멤버가 저널 로그가 없는 경우에는 계속해서 체크포인트를 실행하도록 작동합니다. 그로 인해 체크포인트가 끊임없이 발생하게 되고, 그만큼 디스크 쓰기가 계속해서 많이 발생할 수 있습니다.

만약 의도적으로 저널 로그를 비활성화한 레플리카 셋에서는 `writeConcern`이 (`w:2`, `j:true`) 이상으로 설정되면 복제의 각 멤버는 저널 로그까지의 데이터 동기화를 달성할 수 없습니다. 그래서 이런 경우 에러가 발생하는데, 이 에러를 막기 위해서는 레플리카 셋 설정에서 `writeConcernMajorityJournalDefault` 옵션을 `false`로 설정해야 합니다.

`writeConcern`의 설정이 위와 같은 상황에서 MongoDB 3.2 버전에서 세컨더리 멤버의 저널 로그가 활성화되면 레플리카 셋에서 투표권을 가진 세컨드리 멤버는 체크포인트가 빈번하게 실행되는 대신 이번에는 저널 로그를 매우 빈번하게 디스크로 동기화하도록 변경됩니다. MongoDB 설정 파일의 `storage.journal.commitIntervalMs` 옵션에 설정된 시간과는 무관하게 매우 빈번하게 디스크 쓰기가 발생합니다. 따라서 프라이머리 멤버에서는 `storage.journal.commitIntervalMs` 옵션에 따라 실행되므로 디스크 쓰기가 거의 발생하지 않는 반면, 세컨드리 멤버는 상당한 디스크 쓰기가 발생합니다. 세컨드리 멤버의 디스크 쓰기는 `INSERT`, `UPDATE`, 그리고 `REMOVE` 명령이 실행되는 횟수에 따라서 더 증가하거나 줄어들 수 있습니다. 이러한 과도한 쓰기는 서버의 디스크 구성에 따라 서비스에 미치는 영향도가 커질 수도 있고 작아질 수도 있습니다. 그러나 평상시에 디스크 읽기 및 쓰기가 많은 서버에서는 어느 정도 사용자 쿼리 처리에 영향을 미칠 수 있습니다.

### 🚀 데이터 페이지
---

WiredTiger 스토리지 엔진은 데이터를 저장하기 위해 고정된 크기의 블록(페이지)을 사용하지 않습니다. 그러나 하나의 페이지가 너무 커지는 것을 막기 위해, 페이지의 최대 크기에 대한 제한을 두고 있습니다. 다른 DBMS와는 달리, WiredTiger 스토리지 엔진은 B-Tree의 인터널 노드(브랜치 노드)와 리프 노드의 페이지 크기를 다르게 설정할 수 있습니다. 인터널 페이지와 리프 페이지의 크기를 다르게 설정하는 이유는 인터널 노드가 리프 노드를 구분하는 인덱스 키만 가지기 때문에, 저장되는 데이터가 많지 않아도 되기 때문입니다. 따라서 WiredTiger 스토리지 엔진의 기본값은 인터널 페이지의 최대 크기는 4KB, 리프 페이지의 최대 크기는 32KB입니다.

WiredTiger 스토리지 엔진에서 또 다른 독특한 점은 컬렉션의 데이터 페이지 크기와 인덱스의 페이지 크기를 다르게 설정할 수 있다는 것입니다. WiredTiger 스토리지 엔진이 내부적으로 고정된 페이지 사이즈를 사용하지 않기 때문에, 용도에 따라 페이지 크기를 다양화할 수 있습니다. 컬렉션과 인덱스에 대해 페이지 크기를 변경하려면, 설정 파일에서 `collectionConfig`와 `indexConfig` 옵션을 수정하면 됩니다.

예를 들어, 위 설정은 컬렉션의 데이터를 저장하는 B-Tree에서 인터널 노드는 4KB, 리프 페이지는 64KB로 설정하고, 인덱스를 저장하는 B-Tree의 인터널 노드는 4KB, 리프 페이지는 16KB로 설정합니다. 인덱스와 컬렉션의 페이지 사이즈를 조정할 때는 응용 프로그램이 데이터를 어떤 패턴으로 읽고 변경하는지 확인하는 것이 필요합니다. 대량의 `INSERT`와 분석 또는 배치 작업을 위한 대량의 조회가 주요 접근 패턴이라면 페이지의 크기를 가능한 크게 설정하는 것이 좋습니다. 반면, 주로 소규모의 도큐먼트를 빈번하고 랜덤하게 읽고 변경하는 응용 프로그램에서는 페이지의 크기를 가능한 작게 설정하는 것이 좋습니다.


### 🚀 운영체제 캐시
---

WiredTiger 스토리지 엔진은 내장된 공유 캐시를 가지고 있습니다. 그러나 MongoDB에 내장된 WiredTiger 스토리지 엔진은 운영체제의 캐시를 경유하는 Cached I/O를 기본 옵션으로 사용하고 있습니다. 즉, WiredTiger 스토리지 엔진이 참조하고자 하는 데이터 페이지는 리눅스 커널이 먼저 디스크에서 읽어 자신의 페이지 캐시에 저장하고, 이후 WiredTiger 스토리지 엔진은 리눅스 페이지 캐시에 있는 데이터를 다시 자신의 내장 캐시에 복사합니다. 따라서 결국 참조하고자 하는 데이터는 리눅스의 페이지 캐시와 WiredTiger 스토리지 엔진에 동일하게 복사되어 있습니다. DBMS에서는 이를 더블 버퍼링(Double Buffering)이라고 합니다.

많은 RDBMS에서는 리눅스의 페이지 캐시 사용량을 최소화하기 위해 다양한 방법을 동원하고 있습니다. 비효율적인 메모리 사용으로 인해 메모리가 부족한 경우 일부 메모리 공간을 디스크로 스왑-아웃(Swap-out) 시키는 현상이 발생하기 때문입니다.("Linux page cache insanity") 예를들면 MySQL의 InnoDB 엔진의 경우 innodb_doublewrite 를 OFF로 설정하여 더블 버퍼링을 비활성화 하는 방안도 존재합니다.  

Direct I/O와 Cached I/O의 선택에서 또 하나 중요한 점은 리눅스의 페이지 캐시가 Write-back 모드로 작동한다는 것입니다.  WiredTiger 스토리지 엔진에서 데이터 쓰기를 실행하면 리눅스 서버는 자신의 페이지 캐시에 기록하고 즉시 WiredTiger 스토리지 엔진에 성공 여부를 반환합니다. 그러나 실제 데이터는 아직 디스크에 완전히 기록되지 않은 상태입니다. 따라서 이 상태에서 리눅스 서버가 크래시되거나 응답 불능 상태가 되면 디스크에 완전히 기록되지 못한 데이터는 손실될 수 있습니다. 그러나 이것이 WiredTiger 스토리지 엔진이 커밋된 데이터를 잃게 된다는 의미는 아닙니다. WiredTiger 스토리지 엔진은 트랜잭션 내용을 항상 저널 로그에 먼저 기록해두기 때문에 비정상적으로 종료된 후에는 저널 로그를 이용해 데이터 파일에 기록되지 못한 데이터를 자동으로 복구합니다. 그리고 리눅스 서버는 WiredTiger 스토리지 엔진과는 전혀 무관하게 적절한 시점에 데이터를 디스크에 기록합니다. 따라서 WiredTiger 스토리지 엔진의 디스크 쓰기 과정이 리눅스 페이지 캐시까지만 저장되면 완료되므로 데이터 쓰기가 매우 빠르게 처리됩니다.

WiredTiger 스토리지 엔진이 Direct I/O 방식으로 실행된다고 가정하면 리눅스의 페이지 캐시를 거치지 않고 즉시 디스크로 쓰기를 전달합니다. 그러나 내장 캐시를 가진 RAID 컨트롤러도 Write-back 모드로 작동하면서 응용 프로그램의 쓰기를 자신의 캐시에 복사한 후 즉시 성공 여부를 반환합니다. 그리고 RAID 컨트롤러는 자체적으로 버퍼링된 데이터를 실제 디스크에 기록합니다. 만약 이 상태에서 서버가 크래시되거나 응답 불능 상태가 되면, RAID 컨트롤러에 내장된 배터리가 캐시 메모리에 전원을 공급하여 데이터가 손실되지 않도록 유지합니다. 이후 서버에 다시 전원이 제공되고 작동이 시작되면 RAID 컨트롤러의 캐시에 남아 있는 데이터를 자동으로 디스크에 기록하게 됩니다.

많은 사람들이 Direct I/O가 Cached I/O보다 성능이 빠를 것이라고 기대하고 사용하는 경우가 많습니다. 그러나 실제로 Cached I/O는 리눅스 서버의 메모리까지만 데이터가 전송되지만, Direct I/O는 리눅스 서버의 메모리를 넘어서 RAID 컨트롤러까지 데이터가 전송되므로 훨씬 더 많은 전송 매체를 거치게 됩니다. 따라서 Direct I/O가 Cached I/O보다 성능이 빠를 수는 없습니다. 그럼에도 Direct I/O를 사용하는 이유는 리눅스의 페이지 캐시를 건너뛰면서 더블 버퍼링으로 인한 메모리의 비효율적인 사용, 메모리 디스크 스왑-아웃 등의 현상을 피하고 응용 프로그램 단에서 데이터 동기화를 제어할 수 있기 때문입니다. 요즘은 SSD 드라이브가 많이 사용되면서 RAID 컨트롤러를 장착하지 않는 경우가 많아졌습니다. PCI-e 인터페이스나 NVMe 인터페이스의 SSD를 많이 사용하면서 RAID 컨트롤러를 장착할 필요성이 많이 없어졌습니다.

장 캐시를 가지지 않는 RAID 컨트롤러를 장착한 서버에서 Direct I/O가 작동하는 방식은 다음과 같습니다. 내장된 캐시를 가지지 않는 RAID 컨트롤러는 데이터를 캐시할 수 없기 때문에 응용 프로그램의 쓰기 요청을 디스크로 전달하는 역할만 수행합니다. RAID 컨트롤러가 장착되지 않은 서버에서도 동일한 과정으로 처리됩니다. 따라서 RAID 컨트롤러가 없거나 RAID 컨트롤러가 장착되어 있어도 내장된 캐시가 없는 경우에는 Direct I/O와 Cached I/O의 성능 차이가 훨씬 더 커지게 됩니다. 실제로 RAID 컨트롤러 없이 서버에 직접 장착된 SSD에서 Direct I/O는 300 마이크로초가 걸리는 반면, Cached I/O는 4~5 마이크로초 정도 시간이 걸립니다. 이는 실제로 60~70배 정도의 성능 차이가 발생하는 것입니다. 따라서 만약 MongoDB에 내장된 WiredTiger 스토리지 엔진에서 Direct I/O를 공식적으로 사용할 수 있게 된다 하더라도, 캐시를 장착한 RAID 컨트롤러가 없는 경우에는 Direct I/O를 사용하기 전에 반드시 성능 테스트를 진행해 볼 필요가 있습니다.


### 🚀 압축
---
ㅇㅇㅇ  
ㅇㅇㅇ  


{% assign posts = site.categories.Mongodb %}
{% for post in posts %} {% include archive-single2.html type=page.entries_layout %} {% endfor %}
---
layout: single
title:  "softmax"
typora-root-url: ./
---

소프트맥스는 로짓과 확률 사이의 관계를 정의한다. 

```math
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^n e^{z_j}}, \quad z_i = x_i - x_{\text{max}}
```

나이브한 소프트맥스를 파이토치 문법으로 구현하면 다음과 같다. 

```python
def naive_softmax(x):
	x_max = x.max(dim=1)[0]
  z = x - x_max[:, None]
  numerator = torch.exp(z)
  denominator = numerator.sum(dim=1)
  ret = numerator / denominator[:, None]
  return ret
```

나이브한 소프트맥스의 내부를 확인하면 3개의 루프로 구성이 된다. 

이는 소프트맥스 인자로 글로벌한 값이 2개(최대 값, 합) 있으며, 값들 사이에 의존성이 존재하기 때문이다. 

```python
def naive_softmax(x: torch.Tensor) -> torch.Tensor:
  rows, cols = x.shape

  row_max = torch.zeros(rows)
  for i in range(rows):
  	row_max[i] = float("-inf")
    for j in range(cols):
      if x[i][j] > row_max[i]:
        row_max[i] = x[i][j]

  numerator = torch.zeros_like(x)
  denominator = torch.zeros(rows)
  for i in range(rows):
    for j in range(cols):
      exp_val = torch.exp(x[i][j] - row_max[i]
      numerator[i][j] = exp_val
      denominator[i] += exp_val

  ret = torch.zeros_like(x)
  for i in range(rows):
    for j in range(cols):
      ret[i][j] = numerator[i][j] / denominator[i]

  return ret
```

Flash Attention 논문에서는 온라인 소프트맥스를 제안하였고, 최대값과 합의 루프를 하나로 구성 할 수 있음을 입증하였다.

```python
def online_softmax(x: torch.Tensor) -> torch.Tensor:
  rows, cols = x.shape

  row_max = torch.zeros(rows)
  denominator = torch.zeros(rows)
  for i in range(rows):
  	row_max[i] = float("-inf")
    for j in range(cols):
      if x[i][j] > row_max[i]:
        new_max = x[i][j]
      denominator[i] = denominator[i] * torch.exp(row_max[i] - new_max) + torch.exp(x[i][j] - new_max)
      row_max[i] = new_max
        
  ret = torch.zeros_like(x)
  for i in range(rows):
    for j in range(cols):
      ret[i][j] = (torch.exp(x[i][j] - row_max[i])) / denominator[i]

  return ret
```






















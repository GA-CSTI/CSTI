---
layout: single
title:  "Statistics as a Diagnostic Superpower"
date:   2025-01-15 19:29:41 -0800
---
<p>
Remember that iconic scene when Neo opens his eyes and says to Morpheus, <em>'I know Kung Fu.'</em>? 
By the end of this post, you’ll be able to say something similar: <em>'I know statistics'</em> 
(or at least the basics of it).
</p>
<p>
Do you realize how powerful and impressive it is for an engineer to understand and apply 
statistical methods to solve problems? 
This post aims to introduce statistics in a practical and approachable way for those 
new to it while also refreshing the knowledge of those already familiar.
To illustrate, I’ll use a simple and relatable example involving diagnostic systems.
</p>

<p>
Diagnostics are crucial for monitoring devices as they ensure device health, 
enhance data reliability, and support predictive maintenance. Additionally, 
compliance and safety are key reasons for utilizing diagnostics, especially 
in industries such as automotive, healthcare, and aerospace. These sectors 
rely on diagnostics to meet stringent safety standards and regulations. 
By continuously monitoring devices, diagnostics ensure they operate within 
specified safety parameters.
</p>

<h2>Temperature Diagnostics: A Practical Example</h2>

<p>
Let’s explore an example of a temperature diagnostic. 
Temperature diagnostics are a common yet critical aspect of device monitoring, 
ensuring that systems operate within safe and optimal temperature ranges. 
By examining this example, we will explore how diagnostics help maintain device 
health, enhance data reliability, and support predictive maintenance.
</p>
<h3>Purpose of the Diagnostic</h3>
<p>
This diagnostic assumes there is a well-defined "normal" operating temperature (\( \mu \)), 
and the system is expected to function around this target value with minor fluctuations.
</p>
<p>
It is not designed for systems where the temperature varies widely but remains functional, 
as it would flag significant deviations from \( \mu \) as abnormal.
</p>

<p>
We’ll use basic statistical concepts, but don’t worry—I’ll explain 
everything in a clear and accessible way so that even those without prior knowledge 
can follow along. For those interested in diving deeper, I recommend an excellent 
<a href="https://coursera.org/share/248ecc720118b822e6387bfb044669d8" target="_blank">course</a> 
on Coursera by Luis Serrano. (Not a sponsored recommendation.)
</p>

<h2>Deterministic or Stochastic?</h2>

<p>
When developing a system, one key question is: Is the problem deterministic or stochastic?
In diagnostics, the answer is often stochastic, meaning the process involves some 
randomness. Here’s an analogy: Consider rain as a random process. Measuring every raindrop 
as it falls is impractical, but statistical methods allow us to measure rainfall in sampled areas 
and derive useful insights, enabling data-driven decisions.
</p>

<h3>Statistics and Probability Distributions</h3>

<p>
Statistics often deal with probability distributions. For instance, imagine rainfall across a region. 
Instead of observing every raindrop, we use sampling to estimate the population’s behavior. To ensure accuracy, 
samples should be:
<ol>
<li>Representative of the population,</li>
<li>Randomized to avoid bias, and</li>
<li>Large enough to capture meaningful patterns.</li>
</ol>
</p>

<p>
If rainfall were uniformly distributed, it would simplify predictions. However, in reality, 
distributions often vary. Assuming uniformity when the distribution deviates can lead to poor system 
designs and inaccurate decisions.
</p>

<h3>The Central Limit Theorem (CLT)</h3>

<p>
The <strong>Central Limit Theorem (CLT)</strong> provides a robust foundation for statistical methods. It states 
that regardless of a population's distribution, the sample means will approach a <strong>Normal (Gaussian) 
distribution</strong> as the sample size increases. This allows us to use statistical tools based on normality.
</p>

<h2>Enter the Matrix: Hypothesis Testing</h2>

<p>
We will use <strong>Hypothesis Testing</strong> to analyze the temperature diagnostic problem. 
The first step is defining the hypotheses:
</p>

<ul>
<li>Null Hypothesis (\(H_0\)): The sample mean temperature represents the expected temperature (\(\mu = \mu_0\)).</li>
<li>Alternative Hypothesis (\(H_1\)): The sample mean temperature deviates from the expected temperature (\(\mu \neq \mu_0\)).</li>
</ul>

<p>
The null and alternative hypotheses are mutually exclusive. If we reject \(H_0\), we accept \(H_1\), 
indicating the system may not be operating normally.
</p>

<h3>Formulas</h3>

<p>
Sample Mean:
</p>
$$
\overline{X} = \frac{1}{n}\sum_{i=1}^n X_i
$$

<p>
Sample Standard Deviation:
</p>
$$
S = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2}
$$

<p>
T-Statistic (if standard deviation is unknown):
</p>
$$
T = \frac{\overline{X} - \mu_0}{S/\sqrt{n}}
$$

<h3>Determine the Critical Value</h3>

<p>
Define the significance level (\(\alpha\)), representing the maximum probability of rejecting \(H_0\) when it is true. 
For a two-sided test, the critical values are:
</p>
$$
\pm t_{\alpha/2, n-1}
$$

<p>
Example: With \(\alpha = 0.05\) and \(n = 25\), find \(t_{0.025, 24}\) (approximately \(2.064\)) in a 
<a href="https://math.fandom.com/wiki/T_table" target="_blank">T-table</a>. In other words, we defined
the critical value to be 2.064.
</p>

<p>
Reject \(H_0\) if:
</p>
$$
T \leq -t_{\alpha/2, n-1} \quad \text{or} \quad T \geq t_{\alpha/2, n-1}.
$$

<p>
Otherwise, fail to reject \(H_0\).
</p>

<p>
The <strong>confidence level</strong> and the variability in the data (measured by the standard deviation \( S \)) determine the range of values that are considered "acceptable" around the mean (\( \mu_0 = 75^\circ \text{C} \)).
This range is derived using the <strong>confidence interval</strong>, which provides a statistically-based range around \( \mu_0 \) within which the true population mean is expected to fall with a certain probability (e.g., 95%).
</p>

<h3>How the Range Is Adjusted Using the Confidence Level</h3>

<ol>
  <li><strong>Confidence Interval Formula:</strong>
  <p>
  For a sample mean \( \overline{X} \), the confidence interval is:
  </p>
  $$
  \overline{X} \pm t_{\alpha/2, n-1} \cdot \frac{S}{\sqrt{n}}
  $$
  <ul>
    <li>\( t_{\alpha/2, n-1} \): Critical t-value based on the confidence level and degrees of freedom (\( n-1 \)).</li>
    <li>\( S \): Sample standard deviation (variability in temperature readings).</li>
    <li>\( n \): Sample size (number of temperature readings).</li>
  </ul>
  </li>
  <li><strong>Impact of Confidence Level (\( 1 - \alpha \)):</strong>
  <p>
  - A <strong>higher confidence level</strong> (e.g., 99%) produces a <strong>wider range</strong> because it requires more certainty that the true mean is within the interval.<br>
  - A <strong>lower confidence level</strong> (e.g., 90%) results in a <strong>narrower range</strong> because you are willing to accept a higher chance that the true mean falls outside the interval.
  </p>
  </li>
</ol>

<h3>Example:</h3>
<p>
Let’s assume:
<ul>
  <li>\( \mu_0 = 75^\circ \text{C} \) (expected mean temperature),</li>
  <li>\( S = 2 \) (sample standard deviation),</li>
  <li>\( n = 25 \) (sample size),</li>
  <li>Confidence level = 95%, so \( \alpha = 0.05 \).</li>
</ul>
</p>

<ol>
  <li>Determine the critical \( t \)-value:
  <p>
  For 95% confidence and \( n-1 = 24 \) degrees of freedom, \( t_{0.025, 24} \approx 2.064 \).
  </p>
  </li>
  <li>Calculate the confidence interval:
  <p>
  $$
  75 \pm 2.064 \cdot \frac{2}{\sqrt{25}}
  $$
  Simplify:
  $$
  75 \pm 2.064 \cdot 0.4 = 75 \pm 0.8256
  $$
  </p>
  </li>
</ol>

<p>
<strong>Confidence interval range:</strong>
</p>
$$
[74.17^\circ \text{C}, 75.83^\circ \text{C}]
$$

<h3>Key Takeaways:</h3>
<ul>
  <li>The range around \( \mu_0 \) is determined by the confidence level and variability in the data.</li>
  <li>Adjusting the confidence level changes the width of this range:
    <ul>
      <li>Higher confidence = Wider range.</li>
      <li>Lower confidence = Narrower range.</li>
    </ul>
  </li>
</ul>

<h2>Conclusion</h2>
<p>
In this article, we explored the fundamentals of diagnostics and hypothesis testing through the lens 
of temperature monitoring. By defining a target temperature (\( \mu \)) and leveraging statistical 
tools like the confidence interval and t-statistic, we can detect abnormal behavior in systems where 
stability is critical. This approach provides a robust method for maintaining system health and 
reliability in environments with predictable operating conditions.
</p>
<p>
However, diagnostics must be tailored to the specific needs of a system. For systems with wide 
operating ranges, a different approach may be necessary to accommodate the inherent variability 
in such environments. The flexibility of statistical methods ensures there is always a way to adapt 
and develop suitable solutions.
</p>
<p>
Looking ahead, I plan to post practical examples of diagnostics implementations using 
<strong>C++20</strong> and <strong>Python</strong>. These examples will be available on my 
<a href="https://github.com/gyrok42" target="_blank">GitHub</a> repository to help readers see how these 
concepts translate into real-world code. Stay tuned for updates, and feel free to reach out with 
questions or suggestions!
</p>
<p>
Thank you for reading, and I hope this post has brought you one step closer to saying: 
<em>"I know statistics."</em>
</p>
